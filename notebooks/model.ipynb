{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gideonoludeyi/cosc5p70/blob/main/notebooks/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1af94d-17df-4b5b-9403-c4e3ea4ea2cc",
      "metadata": {
        "id": "dc1af94d-17df-4b5b-9403-c4e3ea4ea2cc"
      },
      "source": [
        "### Data: Predict Students' Dropout and Academic Success\n",
        "\n",
        "@misc{predict_students'_dropout_and_academic_success_697,\n",
        "  author       = {Realinho, Valentim, Vieira Martins, Mónica, Machado, Jorge, and Baptista, Luís},\n",
        "  title        = {{Predict Students' Dropout and Academic Success}},\n",
        "  year         = {2021},\n",
        "  howpublished = {UCI Machine Learning Repository},\n",
        "  note         = {{DOI}: [https://doi.org/10.24432/C5MC89](https://doi.org/10.24432/C5MC89)}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e4192320-b495-4ae6-b151-8ea7f5e54a78",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e4192320-b495-4ae6-b151-8ea7f5e54a78",
        "outputId": "78361dea-e67e-40b9-ce9d-a94c66d6cefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install \"ucimlrepo\" \"pandas\" \"numpy\" \"matplotlib\" \"torch\" \"scikit-learn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2f30f272-815b-4a55-bfa1-f243fd003096",
      "metadata": {
        "id": "2f30f272-815b-4a55-bfa1-f243fd003096"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import random\n",
        "import time\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b14e7db7-6d45-4526-8969-b3a7749dc921",
      "metadata": {
        "id": "b14e7db7-6d45-4526-8969-b3a7749dc921"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset - https://archive.ics.uci.edu/dataset/697\n",
        "repo = fetch_ucirepo(id=697)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = repo.data.features\n",
        "\n",
        "X_norm = nn.functional.normalize(torch.from_numpy(X.values), p=2, dim=1)\n",
        "y = repo.data.targets['Target']\n",
        "\n",
        "X = pd.DataFrame(X_norm.numpy(), columns=X.columns)\n",
        "\n",
        "# metadata\n",
        "# print(repo.metadata)\n",
        "\n",
        "# variable information\n",
        "# print(repo.variables)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([repo.data.features, repo.data.targets['Target']], axis=1)\n",
        "df.to_csv('data.csv', index=True)"
      ],
      "metadata": {
        "id": "B3C0eGnOQV1S"
      },
      "id": "B3C0eGnOQV1S",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f91cf371-1bc9-4356-84d6-d8ceb4e88696",
      "metadata": {
        "id": "f91cf371-1bc9-4356-84d6-d8ceb4e88696"
      },
      "outputs": [],
      "source": [
        "# Fixing the random seed to guarantee deterministic results\n",
        "def set_seed(seed):\n",
        "    import os\n",
        "    import random\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "#seed = 123456789\n",
        "seed = int(time.time() * 1000) % (2**32)\n",
        "\n",
        "set_seed(seed)\n",
        "rng = torch.Generator().manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3dd56486-5312-47b1-9189-2f858ca980ab",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dd56486-5312-47b1-9189-2f858ca980ab",
        "outputId": "8f081501-b931-4ca7-b5d0-3060cac262d0",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4424 entries, 0 to 4423\n",
            "Data columns (total 36 columns):\n",
            " #   Column                                          Non-Null Count  Dtype  \n",
            "---  ------                                          --------------  -----  \n",
            " 0   Marital Status                                  4424 non-null   float64\n",
            " 1   Application mode                                4424 non-null   float64\n",
            " 2   Application order                               4424 non-null   float64\n",
            " 3   Course                                          4424 non-null   float64\n",
            " 4   Daytime/evening attendance                      4424 non-null   float64\n",
            " 5   Previous qualification                          4424 non-null   float64\n",
            " 6   Previous qualification (grade)                  4424 non-null   float64\n",
            " 7   Nacionality                                     4424 non-null   float64\n",
            " 8   Mother's qualification                          4424 non-null   float64\n",
            " 9   Father's qualification                          4424 non-null   float64\n",
            " 10  Mother's occupation                             4424 non-null   float64\n",
            " 11  Father's occupation                             4424 non-null   float64\n",
            " 12  Admission grade                                 4424 non-null   float64\n",
            " 13  Displaced                                       4424 non-null   float64\n",
            " 14  Educational special needs                       4424 non-null   float64\n",
            " 15  Debtor                                          4424 non-null   float64\n",
            " 16  Tuition fees up to date                         4424 non-null   float64\n",
            " 17  Gender                                          4424 non-null   float64\n",
            " 18  Scholarship holder                              4424 non-null   float64\n",
            " 19  Age at enrollment                               4424 non-null   float64\n",
            " 20  International                                   4424 non-null   float64\n",
            " 21  Curricular units 1st sem (credited)             4424 non-null   float64\n",
            " 22  Curricular units 1st sem (enrolled)             4424 non-null   float64\n",
            " 23  Curricular units 1st sem (evaluations)          4424 non-null   float64\n",
            " 24  Curricular units 1st sem (approved)             4424 non-null   float64\n",
            " 25  Curricular units 1st sem (grade)                4424 non-null   float64\n",
            " 26  Curricular units 1st sem (without evaluations)  4424 non-null   float64\n",
            " 27  Curricular units 2nd sem (credited)             4424 non-null   float64\n",
            " 28  Curricular units 2nd sem (enrolled)             4424 non-null   float64\n",
            " 29  Curricular units 2nd sem (evaluations)          4424 non-null   float64\n",
            " 30  Curricular units 2nd sem (approved)             4424 non-null   float64\n",
            " 31  Curricular units 2nd sem (grade)                4424 non-null   float64\n",
            " 32  Curricular units 2nd sem (without evaluations)  4424 non-null   float64\n",
            " 33  Unemployment rate                               4424 non-null   float64\n",
            " 34  Inflation rate                                  4424 non-null   float64\n",
            " 35  GDP                                             4424 non-null   float64\n",
            "dtypes: float64(36)\n",
            "memory usage: 1.2 MB\n"
          ]
        }
      ],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop(columns=['Gender', 'Nacionality'])"
      ],
      "metadata": {
        "id": "_ni_7zvxJMMM"
      },
      "id": "_ni_7zvxJMMM",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7i_IvNaJLr6",
        "outputId": "cf55bc4f-2685-4526-cb65-ce1cbc05c957",
        "collapsed": true
      },
      "id": "W7i_IvNaJLr6",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4424 entries, 0 to 4423\n",
            "Data columns (total 34 columns):\n",
            " #   Column                                          Non-Null Count  Dtype  \n",
            "---  ------                                          --------------  -----  \n",
            " 0   Marital Status                                  4424 non-null   float64\n",
            " 1   Application mode                                4424 non-null   float64\n",
            " 2   Application order                               4424 non-null   float64\n",
            " 3   Course                                          4424 non-null   float64\n",
            " 4   Daytime/evening attendance                      4424 non-null   float64\n",
            " 5   Previous qualification                          4424 non-null   float64\n",
            " 6   Previous qualification (grade)                  4424 non-null   float64\n",
            " 7   Mother's qualification                          4424 non-null   float64\n",
            " 8   Father's qualification                          4424 non-null   float64\n",
            " 9   Mother's occupation                             4424 non-null   float64\n",
            " 10  Father's occupation                             4424 non-null   float64\n",
            " 11  Admission grade                                 4424 non-null   float64\n",
            " 12  Displaced                                       4424 non-null   float64\n",
            " 13  Educational special needs                       4424 non-null   float64\n",
            " 14  Debtor                                          4424 non-null   float64\n",
            " 15  Tuition fees up to date                         4424 non-null   float64\n",
            " 16  Scholarship holder                              4424 non-null   float64\n",
            " 17  Age at enrollment                               4424 non-null   float64\n",
            " 18  International                                   4424 non-null   float64\n",
            " 19  Curricular units 1st sem (credited)             4424 non-null   float64\n",
            " 20  Curricular units 1st sem (enrolled)             4424 non-null   float64\n",
            " 21  Curricular units 1st sem (evaluations)          4424 non-null   float64\n",
            " 22  Curricular units 1st sem (approved)             4424 non-null   float64\n",
            " 23  Curricular units 1st sem (grade)                4424 non-null   float64\n",
            " 24  Curricular units 1st sem (without evaluations)  4424 non-null   float64\n",
            " 25  Curricular units 2nd sem (credited)             4424 non-null   float64\n",
            " 26  Curricular units 2nd sem (enrolled)             4424 non-null   float64\n",
            " 27  Curricular units 2nd sem (evaluations)          4424 non-null   float64\n",
            " 28  Curricular units 2nd sem (approved)             4424 non-null   float64\n",
            " 29  Curricular units 2nd sem (grade)                4424 non-null   float64\n",
            " 30  Curricular units 2nd sem (without evaluations)  4424 non-null   float64\n",
            " 31  Unemployment rate                               4424 non-null   float64\n",
            " 32  Inflation rate                                  4424 non-null   float64\n",
            " 33  GDP                                             4424 non-null   float64\n",
            "dtypes: float64(34)\n",
            "memory usage: 1.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "E_yt27zWxCuu",
        "outputId": "966d1e0d-e37f-4e46-88a1-989c721978b6"
      },
      "id": "E_yt27zWxCuu",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Marital Status  Application mode  Application order       Course  \\\n",
              "count     4424.000000       4424.000000        4424.000000  4424.000000   \n",
              "mean         0.000324          0.004356           0.000477     0.980495   \n",
              "std          0.000860          0.017999           0.001556     0.086786   \n",
              "min          0.000100          0.000100           0.000000     0.151658   \n",
              "25%          0.000105          0.000109           0.000105     0.999746   \n",
              "50%          0.000108          0.001837           0.000110     0.999785   \n",
              "75%          0.000110          0.004263           0.000220     0.999811   \n",
              "max          0.009554          0.262869           0.023949     0.999885   \n",
              "\n",
              "       Daytime/evening attendance  Previous qualification  \\\n",
              "count                 4424.000000             4424.000000   \n",
              "mean                     0.000288                0.001083   \n",
              "std                      0.000838                0.007689   \n",
              "min                      0.000000                0.000100   \n",
              "25%                      0.000103                0.000105   \n",
              "50%                      0.000108                0.000108   \n",
              "75%                      0.000110                0.000111   \n",
              "max                      0.005837                0.204277   \n",
              "\n",
              "       Previous qualification (grade)  Mother's qualification  \\\n",
              "count                     4424.000000             4424.000000   \n",
              "mean                         0.040599                0.005127   \n",
              "std                          0.113942                0.018795   \n",
              "min                          0.009823                0.000100   \n",
              "25%                          0.013309                0.000304   \n",
              "50%                          0.014286                0.002077   \n",
              "75%                          0.015260                0.003999   \n",
              "max                          0.745404                0.221806   \n",
              "\n",
              "       Father's qualification  Mother's occupation  ...  \\\n",
              "count             4424.000000          4424.000000  ...   \n",
              "mean                 0.006014             0.002437  ...   \n",
              "std                  0.021118             0.011086  ...   \n",
              "min                  0.000100             0.000000  ...   \n",
              "25%                  0.000330             0.000421  ...   \n",
              "50%                  0.003120             0.000683  ...   \n",
              "75%                  0.004004             0.000974  ...   \n",
              "max                  0.215969             0.464207  ...   \n",
              "\n",
              "       Curricular units 1st sem (without evaluations)  \\\n",
              "count                                     4424.000000   \n",
              "mean                                         0.000015   \n",
              "std                                          0.000075   \n",
              "min                                          0.000000   \n",
              "25%                                          0.000000   \n",
              "50%                                          0.000000   \n",
              "75%                                          0.000000   \n",
              "max                                          0.001321   \n",
              "\n",
              "       Curricular units 2nd sem (credited)  \\\n",
              "count                          4424.000000   \n",
              "mean                              0.000283   \n",
              "std                               0.002919   \n",
              "min                               0.000000   \n",
              "25%                               0.000000   \n",
              "50%                               0.000000   \n",
              "75%                               0.000000   \n",
              "max                               0.064730   \n",
              "\n",
              "       Curricular units 2nd sem (enrolled)  \\\n",
              "count                          4424.000000   \n",
              "mean                              0.001153   \n",
              "std                               0.004894   \n",
              "min                               0.000000   \n",
              "25%                               0.000550   \n",
              "50%                               0.000649   \n",
              "75%                               0.000748   \n",
              "max                               0.081711   \n",
              "\n",
              "       Curricular units 2nd sem (evaluations)  \\\n",
              "count                             4424.000000   \n",
              "mean                                 0.001482   \n",
              "std                                  0.006274   \n",
              "min                                  0.000000   \n",
              "25%                                  0.000656   \n",
              "50%                                  0.000842   \n",
              "75%                                  0.001093   \n",
              "max                                  0.109082   \n",
              "\n",
              "       Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "count                          4424.000000                       4424.000000   \n",
              "mean                              0.000851                          0.001590   \n",
              "std                               0.004149                          0.005018   \n",
              "min                               0.000000                          0.000000   \n",
              "25%                               0.000219                          0.001137   \n",
              "50%                               0.000541                          0.001314   \n",
              "75%                               0.000660                          0.001443   \n",
              "max                               0.072135                          0.071404   \n",
              "\n",
              "       Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "count                                     4424.000000        4424.000000   \n",
              "mean                                         0.000025           0.003452   \n",
              "std                                          0.000291           0.009820   \n",
              "min                                          0.000000           0.000760   \n",
              "25%                                          0.000000           0.000989   \n",
              "50%                                          0.000000           0.001224   \n",
              "75%                                          0.000000           0.001522   \n",
              "max                                          0.013787           0.094559   \n",
              "\n",
              "       Inflation rate          GDP  \n",
              "count     4424.000000  4424.000000  \n",
              "mean         0.000351     0.000038  \n",
              "std          0.001506     0.002068  \n",
              "min         -0.003446    -0.016213  \n",
              "25%          0.000032    -0.000184  \n",
              "50%          0.000143     0.000035  \n",
              "75%          0.000284     0.000194  \n",
              "max          0.014809     0.019657  \n",
              "\n",
              "[8 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e008302a-5e1b-4d9b-ba72-9f5838da8f5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital Status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>Mother's occupation</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 1st sem (without evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "      <td>4424.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000324</td>\n",
              "      <td>0.004356</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.980495</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.001083</td>\n",
              "      <td>0.040599</td>\n",
              "      <td>0.005127</td>\n",
              "      <td>0.006014</td>\n",
              "      <td>0.002437</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>0.001482</td>\n",
              "      <td>0.000851</td>\n",
              "      <td>0.001590</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.003452</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.000038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.000860</td>\n",
              "      <td>0.017999</td>\n",
              "      <td>0.001556</td>\n",
              "      <td>0.086786</td>\n",
              "      <td>0.000838</td>\n",
              "      <td>0.007689</td>\n",
              "      <td>0.113942</td>\n",
              "      <td>0.018795</td>\n",
              "      <td>0.021118</td>\n",
              "      <td>0.011086</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.002919</td>\n",
              "      <td>0.004894</td>\n",
              "      <td>0.006274</td>\n",
              "      <td>0.004149</td>\n",
              "      <td>0.005018</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.009820</td>\n",
              "      <td>0.001506</td>\n",
              "      <td>0.002068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.009823</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000760</td>\n",
              "      <td>-0.003446</td>\n",
              "      <td>-0.016213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.999746</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.013309</td>\n",
              "      <td>0.000304</td>\n",
              "      <td>0.000330</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>0.000656</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.001137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000989</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>-0.000184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.001837</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.999785</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.014286</td>\n",
              "      <td>0.002077</td>\n",
              "      <td>0.003120</td>\n",
              "      <td>0.000683</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>0.000842</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.001314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001224</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.004263</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.999811</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.015260</td>\n",
              "      <td>0.003999</td>\n",
              "      <td>0.004004</td>\n",
              "      <td>0.000974</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.000660</td>\n",
              "      <td>0.001443</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001522</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>0.000194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.009554</td>\n",
              "      <td>0.262869</td>\n",
              "      <td>0.023949</td>\n",
              "      <td>0.999885</td>\n",
              "      <td>0.005837</td>\n",
              "      <td>0.204277</td>\n",
              "      <td>0.745404</td>\n",
              "      <td>0.221806</td>\n",
              "      <td>0.215969</td>\n",
              "      <td>0.464207</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001321</td>\n",
              "      <td>0.064730</td>\n",
              "      <td>0.081711</td>\n",
              "      <td>0.109082</td>\n",
              "      <td>0.072135</td>\n",
              "      <td>0.071404</td>\n",
              "      <td>0.013787</td>\n",
              "      <td>0.094559</td>\n",
              "      <td>0.014809</td>\n",
              "      <td>0.019657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e008302a-5e1b-4d9b-ba72-9f5838da8f5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e008302a-5e1b-4d9b-ba72-9f5838da8f5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e008302a-5e1b-4d9b-ba72-9f5838da8f5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f56b83fa-9ad4-454d-b5a4-2a1528d40d5a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f56b83fa-9ad4-454d-b5a4-2a1528d40d5a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f56b83fa-9ad4-454d-b5a4-2a1528d40d5a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There are three labels: 'Dropout', 'Enrolled', and 'Graduate'\n",
        "# But there are way more instances of 'Graduate'.\n",
        "#   could it lead to bias in the model?\n",
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Qr6EM8h8xMFt",
        "outputId": "acab6a85-5869-4185-861d-8730605d00b0"
      },
      "id": "Qr6EM8h8xMFt",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Target\n",
              "Graduate    2209\n",
              "Dropout     1421\n",
              "Enrolled     794\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Graduate</th>\n",
              "      <td>2209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dropout</th>\n",
              "      <td>1421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Enrolled</th>\n",
              "      <td>794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e7df060c-a05c-4ba0-911a-097f65fa38c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "e7df060c-a05c-4ba0-911a-097f65fa38c4",
        "outputId": "f1849391-1b9f-4ab9-87d2-469e60d12b40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Marital Status  Application mode  Application order    Course  \\\n",
              "2379        0.000110          0.000110           0.000110  0.999784   \n",
              "15          0.000102          0.000102           0.000102  0.999824   \n",
              "4140        0.000433          0.000757           0.000108  0.999653   \n",
              "1949        0.000105          0.001894           0.000105  0.999828   \n",
              "947         0.000102          0.001739           0.000205  0.999819   \n",
              "2363        0.000110          0.004824           0.000110  0.999736   \n",
              "1404        0.000109          0.004809           0.000109  0.999760   \n",
              "4149        0.000105          0.004525           0.000316  0.999730   \n",
              "689         0.000437          0.004263           0.000219  0.999754   \n",
              "2749        0.000200          0.003903           0.000100  0.999776   \n",
              "\n",
              "      Daytime/evening attendance  Previous qualification  \\\n",
              "2379                    0.000110                0.000110   \n",
              "15                      0.000102                0.000102   \n",
              "4140                    0.000108                0.004328   \n",
              "1949                    0.000105                0.000105   \n",
              "947                     0.000102                0.000102   \n",
              "2363                    0.000110                0.004276   \n",
              "1404                    0.000109                0.004263   \n",
              "4149                    0.000105                0.000105   \n",
              "689                     0.000109                0.002077   \n",
              "2749                    0.000000                0.000100   \n",
              "\n",
              "      Previous qualification (grade)  Mother's qualification  \\\n",
              "2379                        0.014564                0.000219   \n",
              "15                          0.012993                0.001944   \n",
              "4140                        0.014067                0.003679   \n",
              "1949                        0.012103                0.003999   \n",
              "947                         0.013617                0.000307   \n",
              "2363                        0.015349                0.000110   \n",
              "1404                        0.014209                0.000219   \n",
              "4149                        0.014628                0.003999   \n",
              "689                         0.014548                0.004044   \n",
              "2749                        0.015010                0.003703   \n",
              "\n",
              "      Father's qualification  Mother's occupation  ...  \\\n",
              "2379                0.004052             0.000986  ...   \n",
              "15                  0.003785             0.000921  ...   \n",
              "4140                0.003679             0.010713  ...   \n",
              "1949                0.003894             0.000526  ...   \n",
              "947                 0.000512             0.000000  ...   \n",
              "2363                0.002083             0.000439  ...   \n",
              "1404                0.004044             0.000219  ...   \n",
              "4149                0.003894             0.000947  ...   \n",
              "689                 0.004044             0.000984  ...   \n",
              "2749                0.003703             0.000901  ...   \n",
              "\n",
              "      Curricular units 1st sem (without evaluations)  \\\n",
              "2379                                        0.000000   \n",
              "15                                          0.000000   \n",
              "4140                                        0.000000   \n",
              "1949                                        0.000000   \n",
              "947                                         0.000000   \n",
              "2363                                        0.000000   \n",
              "1404                                        0.000000   \n",
              "4149                                        0.000105   \n",
              "689                                         0.000000   \n",
              "2749                                        0.000000   \n",
              "\n",
              "      Curricular units 2nd sem (credited)  \\\n",
              "2379                             0.000000   \n",
              "15                               0.000000   \n",
              "4140                             0.000000   \n",
              "1949                             0.000000   \n",
              "947                              0.000000   \n",
              "2363                             0.000000   \n",
              "1404                             0.000000   \n",
              "4149                             0.001158   \n",
              "689                              0.000000   \n",
              "2749                             0.000000   \n",
              "\n",
              "      Curricular units 2nd sem (enrolled)  \\\n",
              "2379                             0.000657   \n",
              "15                               0.000614   \n",
              "4140                             0.000649   \n",
              "1949                             0.000842   \n",
              "947                              0.000409   \n",
              "2363                             0.000548   \n",
              "1404                             0.000546   \n",
              "4149                             0.001473   \n",
              "689                              0.000546   \n",
              "2749                             0.000500   \n",
              "\n",
              "      Curricular units 2nd sem (evaluations)  \\\n",
              "2379                                0.000876   \n",
              "15                                  0.000716   \n",
              "4140                                0.000000   \n",
              "1949                                0.000947   \n",
              "947                                 0.000818   \n",
              "2363                                0.000658   \n",
              "1404                                0.000546   \n",
              "4149                                0.002736   \n",
              "689                                 0.000984   \n",
              "2749                                0.000600   \n",
              "\n",
              "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "2379                             0.000657                          0.001369   \n",
              "15                               0.000000                          0.000000   \n",
              "4140                             0.000000                          0.000000   \n",
              "1949                             0.000737                          0.001298   \n",
              "947                              0.000000                          0.000000   \n",
              "2363                             0.000219                          0.001279   \n",
              "1404                             0.000000                          0.000000   \n",
              "4149                             0.001263                          0.001412   \n",
              "689                              0.000000                          0.000000   \n",
              "2749                             0.000500                          0.001161   \n",
              "\n",
              "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "2379                                        0.000000           0.001358   \n",
              "15                                          0.000000           0.001586   \n",
              "4140                                        0.000000           0.001201   \n",
              "1949                                        0.000000           0.001631   \n",
              "947                                         0.000000           0.000778   \n",
              "2363                                        0.000000           0.001184   \n",
              "1404                                        0.000000           0.001694   \n",
              "4149                                        0.000105           0.000800   \n",
              "689                                         0.000000           0.001180   \n",
              "2749                                        0.000100           0.000761   \n",
              "\n",
              "      Inflation rate       GDP  \n",
              "2379        0.000055  0.000196  \n",
              "15          0.000286 -0.000415  \n",
              "4140        0.000065  0.000219  \n",
              "1949        0.000295 -0.000427  \n",
              "947         0.000266  0.000033  \n",
              "2363        0.000153  0.000191  \n",
              "1404        0.000306 -0.000444  \n",
              "4149        0.000274  0.000034  \n",
              "689         0.000153  0.000190  \n",
              "2749        0.000260  0.000032  \n",
              "\n",
              "[10 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b6aeec5-c9f6-4284-b9c7-f5ff734ab022\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital Status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>Mother's occupation</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 1st sem (without evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.999784</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.014564</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.004052</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>0.000876</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>0.001369</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001358</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.999824</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.012993</td>\n",
              "      <td>0.001944</td>\n",
              "      <td>0.003785</td>\n",
              "      <td>0.000921</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000614</td>\n",
              "      <td>0.000716</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001586</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>-0.000415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4140</th>\n",
              "      <td>0.000433</td>\n",
              "      <td>0.000757</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.999653</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.004328</td>\n",
              "      <td>0.014067</td>\n",
              "      <td>0.003679</td>\n",
              "      <td>0.003679</td>\n",
              "      <td>0.010713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001201</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.000219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949</th>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.001894</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.999828</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.012103</td>\n",
              "      <td>0.003999</td>\n",
              "      <td>0.003894</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000842</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>0.000737</td>\n",
              "      <td>0.001298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001631</td>\n",
              "      <td>0.000295</td>\n",
              "      <td>-0.000427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>947</th>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.001739</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.999819</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.013617</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000409</td>\n",
              "      <td>0.000818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2363</th>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.004824</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.999736</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.004276</td>\n",
              "      <td>0.015349</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000548</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.001279</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001184</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.000191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.004809</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.999760</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.004263</td>\n",
              "      <td>0.014209</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.004044</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001694</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>-0.000444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4149</th>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.004525</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.999730</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.014628</td>\n",
              "      <td>0.003999</td>\n",
              "      <td>0.003894</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>0.001473</td>\n",
              "      <td>0.002736</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.001412</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000274</td>\n",
              "      <td>0.000034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>0.000437</td>\n",
              "      <td>0.004263</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.002077</td>\n",
              "      <td>0.014548</td>\n",
              "      <td>0.004044</td>\n",
              "      <td>0.004044</td>\n",
              "      <td>0.000984</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.000984</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001180</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.000190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2749</th>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.003903</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.999776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.015010</td>\n",
              "      <td>0.003703</td>\n",
              "      <td>0.003703</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001161</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000761</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.000032</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6aeec5-c9f6-4284-b9c7-f5ff734ab022')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b6aeec5-c9f6-4284-b9c7-f5ff734ab022 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b6aeec5-c9f6-4284-b9c7-f5ff734ab022');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fc93c78-630a-4e82-83db-d7b961e93276\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fc93c78-630a-4e82-83db-d7b961e93276')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fc93c78-630a-4e82-83db-d7b961e93276 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Samples from the data\n",
        "X.sample(10, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d87a92f0-3750-4a03-ab6b-fa9fc070950f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d87a92f0-3750-4a03-ab6b-fa9fc070950f",
        "outputId": "d8f7bb44-7ca1-482f-863d-85c572a94731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 3539 (0.80)\n",
            "Test  set size: 885  (0.20)\n"
          ]
        }
      ],
      "source": [
        "# Data splitting - training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True, random_state=seed)\n",
        "mean = X_train.mean(axis=0)\n",
        "std = X_train.std(axis=0)\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n",
        "\n",
        "print(f\"Train set size: {len(y_train)} ({len(y_train) / len(y):.2f})\")\n",
        "print(f\"Test  set size: {len(y_test)}  ({len(y_test) / len(y):.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_index(label):\n",
        "  map = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}\n",
        "  return map[label]\n",
        "\n",
        "def index_to_label(index):\n",
        "  map = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}\n",
        "  return map[index]"
      ],
      "metadata": {
        "id": "hcSq2C_eBuEv"
      },
      "id": "hcSq2C_eBuEv",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.apply(label_to_index)\n",
        "y_test = y_test.apply(label_to_index)"
      ],
      "metadata": {
        "id": "Hpg0mn6pCAiM"
      },
      "id": "Hpg0mn6pCAiM",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, weights=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.weights = weights\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.CrossEntropyLoss(weight=self.weights)(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return F_loss"
      ],
      "metadata": {
        "id": "l8DjexpQOEHl"
      },
      "id": "l8DjexpQOEHl",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e4d86295-989e-4079-a4dc-27ecdcf23f62",
      "metadata": {
        "id": "e4d86295-989e-4079-a4dc-27ecdcf23f62"
      },
      "outputs": [],
      "source": [
        "class SupervisedDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = np.asarray(X)\n",
        "        self.y = np.asarray(y)\n",
        "        self.transform = transform # function to process the features\n",
        "        #self.target_transform = target_transform # function to process the label\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        features = self.X[index]\n",
        "        label = self.y[index]\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "        #if self.target_transform is not None:\n",
        "        #    label = self.target_transform(label)\n",
        "        return features, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "36e80863-3520-424d-92e8-777f2ae0d810",
      "metadata": {
        "id": "36e80863-3520-424d-92e8-777f2ae0d810"
      },
      "outputs": [],
      "source": [
        "def train_step(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    batch_size = dataloader.batch_size\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Convert X and y to float tensors to match model requirements\n",
        "        X, y = X.clone().detach().float(), y.clone().detach().long()\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % (batch_size // 4) == 0:\n",
        "            loss = loss.item()\n",
        "            current = batch * dataloader.batch_size + len(X)\n",
        "            #print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_step(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    return test_loss, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "caf18e47-e8db-466f-9679-830702328f41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caf18e47-e8db-466f-9679-830702328f41",
        "outputId": "8bb04de1-3dbb-4800-9ab5-afe677cdd12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dimensions: 34\n",
            "Sequential(\n",
            "  (0): Linear(in_features=34, out_features=256, bias=True)\n",
            "  (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Dropout(p=0.3, inplace=False)\n",
            "  (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): ReLU()\n",
            "  (7): Dropout(p=0.3, inplace=False)\n",
            "  (8): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): ReLU()\n",
            "  (11): Dropout(p=0.3, inplace=False)\n",
            "  (12): Linear(in_features=64, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Neural network architecture (36 x 256 x 128 x 64 x 3)\n",
        "\n",
        "input_dimensions = np.shape(X_train)[1]\n",
        "\n",
        "print(f\"Input dimensions: {input_dimensions}\")\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(input_dimensions, 256),  # First hidden layer\n",
        "    nn.BatchNorm1d(256),               # Normalize activations\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),                   # Regularization\n",
        "    nn.Linear(256, 128),                # Second hidden layer\n",
        "    nn.BatchNorm1d(128),                # Normalize activations\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(128, 64),               # Third hidden layer\n",
        "    nn.BatchNorm1d(64),                # Normalize activations\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(64, 3)                   # Output layer\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 1000\n",
        "momentum=0.9\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "qYeY-pk1CFfl"
      },
      "id": "qYeY-pk1CFfl",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_train = np.unique(y_train)\n",
        "loss_weights = compute_class_weight('balanced', classes=classes_train, y=y_train)\n",
        "loss_weights = torch.tensor(loss_weights, dtype=torch.float32)\n",
        "print(f\"Classes:      {classes_train}\")\n",
        "print(f\"Loss Weights: {loss_weights}\")\n",
        "\n",
        "# Loss function\n",
        "#  assign weights labels due to imbalance in labels\n",
        "#  e.g., there are more 'Graduate' instances than 'Enrolled' and 'Dropout'\n",
        "#        so 'Graduate' label is assigned a lower weight in term of loss\n",
        "loss_fn = FocalLoss(alpha=1, gamma=2, weights=loss_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDDKHLPFywn8",
        "outputId": "ee96dceb-e717-4433-f813-50e7c736d965"
      },
      "id": "NDDKHLPFywn8",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes:      [0 1 2]\n",
            "Loss Weights: tensor([1.0375, 1.8577, 0.6676])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
      ],
      "metadata": {
        "id": "daXTDIoYCODb"
      },
      "id": "daXTDIoYCODb",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "72aae356-f66d-4268-849a-bb58aeab2b4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72aae356-f66d-4268-849a-bb58aeab2b4f",
        "outputId": "4db69e4a-872f-4a09-db77-0abcd6c7c5cc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-8b5855e6d512>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X, y = torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 49.6%, avg.loss: 0.488147 \n",
            "\n",
            "Validation loss improved to 49.6%\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 69.2%, avg.loss: 0.240170 \n",
            "\n",
            "Validation loss improved to 69.2%\n",
            "Epoch 101\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 67.8%, avg.loss: 0.216401 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.3%\n",
            "Epoch 151\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 68.5%, avg.loss: 0.218254 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.3%\n",
            "Epoch 201\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 69.5%, avg.loss: 0.212049 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 251\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 69.6%, avg.loss: 0.208057 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 301\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 68.7%, avg.loss: 0.217219 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 351\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 66.3%, avg.loss: 0.235863 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 401\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 68.0%, avg.loss: 0.220250 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 451\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 67.0%, avg.loss: 0.225878 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 501\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 67.6%, avg.loss: 0.222997 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 551\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 69.8%, avg.loss: 0.220412 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 601\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 67.1%, avg.loss: 0.222224 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 651\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 65.0%, avg.loss: 0.229177 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 701\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 64.7%, avg.loss: 0.243768 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 751\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 65.3%, avg.loss: 0.229223 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 801\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 65.6%, avg.loss: 0.231528 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 851\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 65.4%, avg.loss: 0.245487 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 901\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 61.2%, avg.loss: 0.247877 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n",
            "Epoch 951\n",
            "-------------------------------\n",
            "Test Error: \n",
            " test_loss: 65.5%, avg.loss: 0.250163 \n",
            "\n",
            "No improvement. Best accuracy is still: 70.6%\n"
          ]
        }
      ],
      "source": [
        "train_data = SupervisedDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, generator=rng)\n",
        "\n",
        "test_data = SupervisedDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, generator=rng)\n",
        "\n",
        "best_accuracy = float('-inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training step\n",
        "    train_step(train_dataloader, model, loss_fn, optimizer)\n",
        "    # Validation step\n",
        "    test_loss, accuracy = test_step(test_dataloader, model, loss_fn)\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "      print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "      print(f\"Test Error: \\n test_loss: {(100*accuracy):>0.1f}%, avg.loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    # Below simply stops the training process if no improvement has happened for a while\n",
        "    # This way, if we oscillate, we only take the best weights before decreasing\n",
        "    # Check if validation loss improved\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy  # Update the best validation loss\n",
        "        # Save the model with the best performance\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        if epoch % 50 == 0:\n",
        "          print(f\"Validation loss improved to {(100*best_accuracy):>0.1f}%\")\n",
        "    else:\n",
        "        if epoch % 50 == 0:\n",
        "          print(f\"No improvement. Best accuracy is still: {(100*best_accuracy):>0.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X):\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X, dtype=torch.float32)\n",
        "        pred = model(X)\n",
        "        y_pred = pred.argmax(1)\n",
        "    return np.asarray(y_pred)\n",
        "\n",
        "def get_result(model, features_df, y_true):\n",
        "    X = features_df.values\n",
        "    y_pred = predict(model, X)\n",
        "    result_df = features_df.copy()\n",
        "    result_df['y_true'] = y_true\n",
        "    result_df['y_true'] = result_df['y_true'].apply(index_to_label)\n",
        "    result_df['y_pred'] = y_pred\n",
        "    result_df['y_pred'] = result_df['y_pred'].apply(index_to_label)\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "sQUnbVf6Gdr7"
      },
      "id": "sQUnbVf6Gdr7",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result_df = get_result(model, X_test, y_test.values)\n",
        "test_result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "_Dh4CMEVP8q-",
        "outputId": "aef8eb38-f367-45f5-efaa-5d3e489543bc"
      },
      "id": "_Dh4CMEVP8q-",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Marital Status  Application mode  Application order    Course  \\\n",
              "4361       -0.250289         -0.141170          -0.239107  0.217203   \n",
              "1934       -0.250284         -0.233372          -0.025716  0.217675   \n",
              "0           4.320365          3.505920          13.285044 -3.359775   \n",
              "2898       -0.250286         -0.135405           0.116534  0.217478   \n",
              "1029       -0.250284         -0.233372          -0.025716  0.217673   \n",
              "...              ...               ...                ...       ...   \n",
              "3308       -0.250287         -0.233372           0.116532  0.217417   \n",
              "4113        0.115177         -0.015697          -0.168806  0.217824   \n",
              "2896       -0.256320         -0.025432          -0.242601  0.217451   \n",
              "3999       -0.250291         -0.141171           0.116519  0.217073   \n",
              "4217       -0.253712         -0.233533          -0.171947  0.217812   \n",
              "\n",
              "      Daytime/evening attendance  Previous qualification  \\\n",
              "4361                   -0.213487               -0.125630   \n",
              "1934                   -0.213482               -0.125630   \n",
              "0                       4.516039                0.351037   \n",
              "2898                   -0.213484               -0.125630   \n",
              "1029                   -0.213482               -0.125630   \n",
              "...                          ...                     ...   \n",
              "3308                   -0.213485               -0.125630   \n",
              "4113                   -0.214225               -0.125704   \n",
              "2896                   -0.340527               -0.126259   \n",
              "3999                   -0.213488               -0.125630   \n",
              "4217                   -0.217029               -0.125987   \n",
              "\n",
              "      Previous qualification (grade)  Mother's qualification  \\\n",
              "4361                       -0.218200               -0.253267   \n",
              "1934                       -0.229370               -0.166372   \n",
              "0                           4.025572                3.674972   \n",
              "2898                       -0.222892               -0.253267   \n",
              "1029                       -0.226646               -0.264128   \n",
              "...                              ...                     ...   \n",
              "3308                       -0.222893               -0.166374   \n",
              "4113                       -0.230101               -0.064392   \n",
              "2896                       -0.247213               -0.078495   \n",
              "3999                       -0.216323               -0.264128   \n",
              "4217                       -0.233864               -0.264280   \n",
              "\n",
              "      Father's qualification  Mother's occupation  ...  \\\n",
              "4361               -0.268938            -0.186037  ...   \n",
              "1934               -0.090476            -0.124665  ...   \n",
              "0                   2.054752             1.472187  ...   \n",
              "2898               -0.187357            -0.177270  ...   \n",
              "1029               -0.279135            -0.124665  ...   \n",
              "...                      ...                  ...  ...   \n",
              "3308               -0.187357            -0.194804  ...   \n",
              "4113               -0.096678            -0.142559  ...   \n",
              "2896               -0.104850            -0.153553  ...   \n",
              "3999               -0.090486            -0.168504  ...   \n",
              "4217               -0.274321            -0.126868  ...   \n",
              "\n",
              "      Curricular units 2nd sem (enrolled)  \\\n",
              "4361                            -0.064571   \n",
              "1934                            -0.064564   \n",
              "0                               -0.232339   \n",
              "2898                            -0.064567   \n",
              "1029                            -0.064564   \n",
              "...                                   ...   \n",
              "3308                            -0.064568   \n",
              "4113                            -0.086394   \n",
              "2896                            -0.132635   \n",
              "3999                            -0.064573   \n",
              "4217                            -0.110021   \n",
              "\n",
              "      Curricular units 2nd sem (evaluations)  \\\n",
              "4361                               -0.101673   \n",
              "1934                               -0.052572   \n",
              "0                                  -0.232588   \n",
              "2898                               -0.101670   \n",
              "1029                               -0.101667   \n",
              "...                                      ...   \n",
              "3308                               -0.101670   \n",
              "4113                               -0.232588   \n",
              "2896                               -0.139225   \n",
              "3999                               -0.101674   \n",
              "4217                               -0.137139   \n",
              "\n",
              "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "4361                            -0.002486                         -0.037156   \n",
              "1934                            -0.027420                         -0.048021   \n",
              "0                               -0.202016                         -0.315373   \n",
              "2898                            -0.027423                         -0.056602   \n",
              "1029                            -0.027420                         -0.037837   \n",
              "...                                   ...                               ...   \n",
              "3308                            -0.002482                         -0.035717   \n",
              "4113                            -0.202016                         -0.315373   \n",
              "2896                            -0.083436                         -0.077531   \n",
              "3999                            -0.002488                         -0.019129   \n",
              "4217                            -0.056541                         -0.041823   \n",
              "\n",
              "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "4361                                       -0.082704          -0.247596   \n",
              "1934                                       -0.082704          -0.214993   \n",
              "0                                          -0.082704           4.136496   \n",
              "2898                                       -0.082704          -0.211735   \n",
              "1029                                       -0.082704          -0.211733   \n",
              "...                                              ...                ...   \n",
              "3308                                       -0.082704          -0.247594   \n",
              "4113                                       -0.082704          -0.233065   \n",
              "2896                                       -0.082704          -0.206119   \n",
              "3999                                       -0.082704          -0.198701   \n",
              "4217                                       -0.082704          -0.250444   \n",
              "\n",
              "      Inflation rate       GDP    y_true    y_pred  \n",
              "4361       -0.289769 -0.197301  Graduate  Graduate  \n",
              "1934       -0.196728  0.065130  Graduate  Enrolled  \n",
              "0           3.597828  3.524652   Dropout   Dropout  \n",
              "2898        0.032295 -0.121408  Graduate  Graduate  \n",
              "1029        0.032300 -0.121409  Graduate  Graduate  \n",
              "...              ...       ...       ...       ...  \n",
              "3308       -0.289770 -0.197304  Graduate  Graduate  \n",
              "4113       -0.132900  0.061913   Dropout   Dropout  \n",
              "2896       -0.252930  0.009604  Enrolled  Enrolled  \n",
              "3999       -0.253984  0.011678   Dropout  Graduate  \n",
              "4217       -0.288172 -0.192651  Graduate  Graduate  \n",
              "\n",
              "[885 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e32deb7-412e-4828-9a00-8cb6d04726ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital Status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>Mother's occupation</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4361</th>\n",
              "      <td>-0.250289</td>\n",
              "      <td>-0.141170</td>\n",
              "      <td>-0.239107</td>\n",
              "      <td>0.217203</td>\n",
              "      <td>-0.213487</td>\n",
              "      <td>-0.125630</td>\n",
              "      <td>-0.218200</td>\n",
              "      <td>-0.253267</td>\n",
              "      <td>-0.268938</td>\n",
              "      <td>-0.186037</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064571</td>\n",
              "      <td>-0.101673</td>\n",
              "      <td>-0.002486</td>\n",
              "      <td>-0.037156</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.247596</td>\n",
              "      <td>-0.289769</td>\n",
              "      <td>-0.197301</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1934</th>\n",
              "      <td>-0.250284</td>\n",
              "      <td>-0.233372</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>0.217675</td>\n",
              "      <td>-0.213482</td>\n",
              "      <td>-0.125630</td>\n",
              "      <td>-0.229370</td>\n",
              "      <td>-0.166372</td>\n",
              "      <td>-0.090476</td>\n",
              "      <td>-0.124665</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064564</td>\n",
              "      <td>-0.052572</td>\n",
              "      <td>-0.027420</td>\n",
              "      <td>-0.048021</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.214993</td>\n",
              "      <td>-0.196728</td>\n",
              "      <td>0.065130</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Enrolled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.320365</td>\n",
              "      <td>3.505920</td>\n",
              "      <td>13.285044</td>\n",
              "      <td>-3.359775</td>\n",
              "      <td>4.516039</td>\n",
              "      <td>0.351037</td>\n",
              "      <td>4.025572</td>\n",
              "      <td>3.674972</td>\n",
              "      <td>2.054752</td>\n",
              "      <td>1.472187</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.232339</td>\n",
              "      <td>-0.232588</td>\n",
              "      <td>-0.202016</td>\n",
              "      <td>-0.315373</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>4.136496</td>\n",
              "      <td>3.597828</td>\n",
              "      <td>3.524652</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>-0.250286</td>\n",
              "      <td>-0.135405</td>\n",
              "      <td>0.116534</td>\n",
              "      <td>0.217478</td>\n",
              "      <td>-0.213484</td>\n",
              "      <td>-0.125630</td>\n",
              "      <td>-0.222892</td>\n",
              "      <td>-0.253267</td>\n",
              "      <td>-0.187357</td>\n",
              "      <td>-0.177270</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064567</td>\n",
              "      <td>-0.101670</td>\n",
              "      <td>-0.027423</td>\n",
              "      <td>-0.056602</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.211735</td>\n",
              "      <td>0.032295</td>\n",
              "      <td>-0.121408</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>-0.250284</td>\n",
              "      <td>-0.233372</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>0.217673</td>\n",
              "      <td>-0.213482</td>\n",
              "      <td>-0.125630</td>\n",
              "      <td>-0.226646</td>\n",
              "      <td>-0.264128</td>\n",
              "      <td>-0.279135</td>\n",
              "      <td>-0.124665</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064564</td>\n",
              "      <td>-0.101667</td>\n",
              "      <td>-0.027420</td>\n",
              "      <td>-0.037837</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.211733</td>\n",
              "      <td>0.032300</td>\n",
              "      <td>-0.121409</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3308</th>\n",
              "      <td>-0.250287</td>\n",
              "      <td>-0.233372</td>\n",
              "      <td>0.116532</td>\n",
              "      <td>0.217417</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>-0.125630</td>\n",
              "      <td>-0.222893</td>\n",
              "      <td>-0.166374</td>\n",
              "      <td>-0.187357</td>\n",
              "      <td>-0.194804</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064568</td>\n",
              "      <td>-0.101670</td>\n",
              "      <td>-0.002482</td>\n",
              "      <td>-0.035717</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.247594</td>\n",
              "      <td>-0.289770</td>\n",
              "      <td>-0.197304</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4113</th>\n",
              "      <td>0.115177</td>\n",
              "      <td>-0.015697</td>\n",
              "      <td>-0.168806</td>\n",
              "      <td>0.217824</td>\n",
              "      <td>-0.214225</td>\n",
              "      <td>-0.125704</td>\n",
              "      <td>-0.230101</td>\n",
              "      <td>-0.064392</td>\n",
              "      <td>-0.096678</td>\n",
              "      <td>-0.142559</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.086394</td>\n",
              "      <td>-0.232588</td>\n",
              "      <td>-0.202016</td>\n",
              "      <td>-0.315373</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.233065</td>\n",
              "      <td>-0.132900</td>\n",
              "      <td>0.061913</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2896</th>\n",
              "      <td>-0.256320</td>\n",
              "      <td>-0.025432</td>\n",
              "      <td>-0.242601</td>\n",
              "      <td>0.217451</td>\n",
              "      <td>-0.340527</td>\n",
              "      <td>-0.126259</td>\n",
              "      <td>-0.247213</td>\n",
              "      <td>-0.078495</td>\n",
              "      <td>-0.104850</td>\n",
              "      <td>-0.153553</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.132635</td>\n",
              "      <td>-0.139225</td>\n",
              "      <td>-0.083436</td>\n",
              "      <td>-0.077531</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.206119</td>\n",
              "      <td>-0.252930</td>\n",
              "      <td>0.009604</td>\n",
              "      <td>Enrolled</td>\n",
              "      <td>Enrolled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>-0.250291</td>\n",
              "      <td>-0.141171</td>\n",
              "      <td>0.116519</td>\n",
              "      <td>0.217073</td>\n",
              "      <td>-0.213488</td>\n",
              "      <td>-0.125630</td>\n",
              "      <td>-0.216323</td>\n",
              "      <td>-0.264128</td>\n",
              "      <td>-0.090486</td>\n",
              "      <td>-0.168504</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064573</td>\n",
              "      <td>-0.101674</td>\n",
              "      <td>-0.002488</td>\n",
              "      <td>-0.019129</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.198701</td>\n",
              "      <td>-0.253984</td>\n",
              "      <td>0.011678</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4217</th>\n",
              "      <td>-0.253712</td>\n",
              "      <td>-0.233533</td>\n",
              "      <td>-0.171947</td>\n",
              "      <td>0.217812</td>\n",
              "      <td>-0.217029</td>\n",
              "      <td>-0.125987</td>\n",
              "      <td>-0.233864</td>\n",
              "      <td>-0.264280</td>\n",
              "      <td>-0.274321</td>\n",
              "      <td>-0.126868</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.110021</td>\n",
              "      <td>-0.137139</td>\n",
              "      <td>-0.056541</td>\n",
              "      <td>-0.041823</td>\n",
              "      <td>-0.082704</td>\n",
              "      <td>-0.250444</td>\n",
              "      <td>-0.288172</td>\n",
              "      <td>-0.192651</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>885 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e32deb7-412e-4828-9a00-8cb6d04726ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e32deb7-412e-4828-9a00-8cb6d04726ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e32deb7-412e-4828-9a00-8cb6d04726ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2a1f283-ee9d-4cca-b5a8-a8682be299ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2a1f283-ee9d-4cca-b5a8-a8682be299ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2a1f283-ee9d-4cca-b5a8-a8682be299ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_92a0f54a-5e07-4935-9fd1-748c267d4388\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_92a0f54a-5e07-4935-9fd1-748c267d4388 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_result_df"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This calculates Predictive parity according to the formula\n",
        "# PP = (number of true prediction)/(total number) per group\n",
        "# The result slightly not fair to group 1 ()\n",
        "\n",
        "predictive_parity = test_result_df.groupby(test_result_df['International']).apply(\n",
        "    lambda group: (group['y_true'] == group['y_pred']).mean()\n",
        ").rename(\"Predictive Parity\")\n",
        "\n",
        "predictive_parity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "Uq3kQHKyuS__",
        "outputId": "80f10ffd-7db5-4f16-cf98-beca3d1e28d8"
      },
      "id": "Uq3kQHKyuS__",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-80a1dd22a169>:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  predictive_parity = test_result_df.groupby(test_result_df['International']).apply(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "International\n",
              "-0.060837     0.618497\n",
              " 0.407054     0.000000\n",
              " 0.413557     0.000000\n",
              " 0.417456     1.000000\n",
              " 0.417470     1.000000\n",
              " 0.422554     0.000000\n",
              " 0.422574     1.000000\n",
              " 0.422579     1.000000\n",
              " 0.428300     0.000000\n",
              " 0.428311     1.000000\n",
              " 0.431059     1.000000\n",
              " 0.431248     1.000000\n",
              " 0.444303     0.000000\n",
              " 0.445157     1.000000\n",
              " 0.445169     1.000000\n",
              " 0.450208     1.000000\n",
              " 0.451183     1.000000\n",
              " 0.451774     1.000000\n",
              " 0.453595     0.000000\n",
              " 0.453659     0.000000\n",
              " 15.494988    1.000000\n",
              "Name: Predictive Parity, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictive Parity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>International</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-0.060837</th>\n",
              "      <td>0.618497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.407054</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.413557</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.417456</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.417470</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.422554</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.422574</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.422579</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.428300</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.428311</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.431059</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.431248</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.444303</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.445157</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.445169</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.450208</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.451183</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.451774</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.453595</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.453659</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15.494988</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_result_df.to_csv('test_result.csv', index=True)"
      ],
      "metadata": {
        "id": "nCl9dU9VP9c8"
      },
      "id": "nCl9dU9VP9c8",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "from google.colab import files\n",
        "files.download(\"model.pth\")"
      ],
      "metadata": {
        "id": "vVp-292RHpFn"
      },
      "id": "vVp-292RHpFn",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def plot_precision_recall_fscore(y_true, y_pred, ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(layout='constrained')\n",
        "\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    labels = (\"Graduate\", \"Enrolled\", \"Dropout\")\n",
        "    penguin_means = {\n",
        "        'Precision': (precision[0], precision[1], precision[2]),\n",
        "        'Recall': (recall[0], recall[1], recall[2]),\n",
        "        'F-score': (fscore[0], fscore[1], fscore[2]),\n",
        "    }\n",
        "\n",
        "    x = np.arange(len(labels))  # the label locations\n",
        "    width = 0.25  # the width of the bars\n",
        "    multiplier = 0\n",
        "\n",
        "    for attribute, measurement in penguin_means.items():\n",
        "        offset = width * multiplier\n",
        "        rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
        "        ax.bar_label(rects, padding=3, fmt='%.2f')\n",
        "        multiplier += 1\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title('Precision, Recall, F1-Score by labels')\n",
        "    ax.set_xticks(x + width, labels)\n",
        "    ax.legend(loc='upper left', ncols=3)\n",
        "    ax.set_ylim(0, 1)\n",
        "\n",
        "    return ax\n",
        "\n",
        "plot_precision_recall_fscore(test_result_df['y_true'].values, test_result_df['y_pred'].values)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "ARwlTusnKM9G",
        "outputId": "d006081e-9bce-45ae-c575-c22380f3f1bf"
      },
      "id": "ARwlTusnKM9G",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean.to_csv('mean.csv', index=True)\n",
        "std.to_csv('std.csv', index=True)"
      ],
      "metadata": {
        "id": "N2H-TIMHMR1p"
      },
      "id": "N2H-TIMHMR1p",
      "execution_count": 33,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}